# å¤è¯—è¯æ™ºèƒ½åˆ†æå·¥å…·ä½¿ç”¨æŒ‡å—

## å·¥å…·æ¦‚è¿°

æœ¬å·¥å…·æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„å¤è¯—è¯åˆ†æç³»ç»Ÿï¼Œèƒ½å¤Ÿè‡ªåŠ¨åˆ†æè¯—è¯å†…å®¹ï¼Œæ ¹æ®é£æ ¼ã€åœºæ™¯ã€ç±»å‹ç­‰ç»´åº¦ä¸ºæ•°æ®å¢åŠ æ›´å¤šæ™ºèƒ½æ ‡ç­¾ï¼Œæå¤§ä¸°å¯Œè¯—è¯æ•°æ®çš„æ£€ç´¢å’Œåˆ†ç±»èƒ½åŠ›ã€‚

## åŠŸèƒ½ç‰¹æ€§

### ğŸ¯ æ™ºèƒ½åˆ†æç»´åº¦
- **é£æ ¼åˆ†æ**: è±ªæ”¾ã€å©‰çº¦ã€ç”°å›­ã€è¾¹å¡ã€å’å²ã€æŠ’æƒ…ã€å†™æ™¯
- **åœºæ™¯åˆ†æ**: æ˜¥å¤©ã€å¤å¤©ã€ç§‹å¤©ã€å†¬å¤©ã€å¤œæ™šã€æ—©æ™¨ã€å±±æ°´ã€åŸå¸‚ã€ä¹¡æ‘
- **æƒ…æ„Ÿåˆ†æ**: å–œæ‚¦ã€å¿§æ„ã€æ€å¿µã€å­¤ç‹¬ã€è±ªè¿ˆã€é—²é€‚
- **ä¸»é¢˜åˆ†æ**: çˆ±æƒ…ã€å‹æƒ…ã€å®¶å›½ã€äººç”Ÿã€è‡ªç„¶ã€å“²ç†
- **ä¿®è¾åˆ†æ**: æ¯”å–»ã€å¯¹ä»—ã€å¤¸å¼ ã€æ‹Ÿäººã€å€Ÿä»£
- **å¤æ‚åº¦è¯„åˆ†**: 0-10åˆ†çš„å¤æ‚åº¦è¯„ä¼°
- **é•¿åº¦åˆ†ç±»**: çŸ­è¯—ã€ä¸­è¯—ã€é•¿è¯—ã€è¶…é•¿è¯—

### ğŸ” å¢å¼ºæœç´¢èƒ½åŠ›
é€šè¿‡æ™ºèƒ½æ ‡ç­¾ï¼Œå¯ä»¥å®ç°æ›´ç²¾ç¡®çš„å¤šç»´åº¦æœç´¢ï¼š
- æŒ‰é£æ ¼æœç´¢ï¼š`è±ªæ”¾é£æ ¼çš„è¯—`
- æŒ‰åœºæ™¯æœç´¢ï¼š`æ˜¥å¤©çš„è¯—`ã€`å¤œæ™šçš„è¯—`
- æŒ‰æƒ…æ„Ÿæœç´¢ï¼š`å¿§æ„çš„è¯—`ã€`å–œæ‚¦çš„è¯—`
- ç»„åˆæœç´¢ï¼š`æ˜¥å¤©+å©‰çº¦+å¿§æ„çš„è¯—`

## å®‰è£…ä¾èµ–

```bash
# å®‰è£…jiebaåˆ†è¯åº“
pip install jieba

# æˆ–è€…ä½¿ç”¨conda
conda install jieba
```

## å¿«é€Ÿå¼€å§‹

### 1. å•é¦–è¯—è¯åˆ†ææ¼”ç¤º

```bash
python poem_analyzer_demo.py
```

è¿™å°†æ¼”ç¤ºå¦‚ä½•åˆ†æå•é¦–è¯—è¯ï¼ˆå¦‚ã€Šé™å¤œæ€ã€‹ï¼‰å¹¶å±•ç¤ºåˆ†æç»“æœã€‚

### 2. æ‰¹é‡åˆ†æå…¨éƒ¨æ•°æ®

```bash
python poem_analyzer.py
```

è¿™å°†åˆ†æå…¨éƒ¨43,103é¦–è¯—è¯æ•°æ®ï¼Œç”Ÿæˆå¢å¼ºçš„æ•°æ®æ–‡ä»¶ã€‚

### 3. è‡ªå®šä¹‰åˆ†ææ ·æœ¬

åœ¨ `poem_analyzer.py` ä¸­ä¿®æ”¹ `sample_size` å‚æ•°ï¼š

```python
# åˆ†æå‰1000é¦–è¯—è¯è¿›è¡Œæµ‹è¯•
sample_size = 1000

# åˆ†æå…¨éƒ¨è¯—è¯
sample_size = None
```

## è¾“å‡ºæ–‡ä»¶

åˆ†æå®Œæˆåä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

### 1. å¢å¼ºæ•°æ®æ–‡ä»¶
- **æ–‡ä»¶**: `website_data/enhanced_poems_data.json`
- **å†…å®¹**: åŒ…å«åŸå§‹æ•°æ® + æ™ºèƒ½åˆ†ææ ‡ç­¾
- **ç»“æ„**:
```json
{
  "title": "é™å¤œæ€",
  "author": "æç™½",
  "paragraphs": ["..."],
  "analysis": {
    "styles": ["æŠ’æƒ…", "å†™æ™¯"],
    "scenes": ["å¤œæ™š"],
    "emotions": ["æ€å¿µ"],
    "themes": ["äººç”Ÿ"],
    "complexity_score": 6.5
  },
  "enhanced_tags": {
    "styles": ["æŠ’æƒ…", "å†™æ™¯"],
    "scenes": ["å¤œæ™š"],
    "emotions": ["æ€å¿µ"],
    "themes": ["äººç”Ÿ"],
    "rhetoric": ["æ¯”å–»"],
    "complexity": 6.5,
    "length_category": "çŸ­è¯—"
  }
}
```

### 2. åˆ†æç»Ÿè®¡æ–‡ä»¶
- **æ–‡ä»¶**: `website_data/analysis_statistics.json`
- **å†…å®¹**: æ•´ä½“åˆ†æç»Ÿè®¡ä¿¡æ¯
- **ç”¨é€”**: äº†è§£æ•°æ®é›†çš„æ•´ä½“ç‰¹å¾åˆ†å¸ƒ

## é›†æˆåˆ°ç½‘ç«™

### 1. æ›´æ–°ç½‘ç«™æ•°æ®

å°†å¢å¼ºæ•°æ®æ–‡ä»¶å¤åˆ¶åˆ°ç½‘ç«™ç›®å½•ï¼š

```bash
# Windows
copy website_data\enhanced_poems_data.json website\data\

# Linux/Mac
cp website_data/enhanced_poems_data.json website/data/
```

### 2. ä¿®æ”¹ç½‘ç«™æœç´¢åŠŸèƒ½

åœ¨ `website/app.js` ä¸­æ·»åŠ æ–°çš„æœç´¢ç»´åº¦ï¼š

```javascript
// åœ¨setupSearchæ–¹æ³•ä¸­æ·»åŠ æ–°çš„æœç´¢å­—æ®µ
const options = {
    keys: [
        'title', 
        'author', 
        'content', 
        'keywords',
        'enhanced_tags.styles',    // æ–°å¢ï¼šé£æ ¼æœç´¢
        'enhanced_tags.scenes',    // æ–°å¢ï¼šåœºæ™¯æœç´¢
        'enhanced_tags.emotions',  // æ–°å¢ï¼šæƒ…æ„Ÿæœç´¢
        'enhanced_tags.themes'     // æ–°å¢ï¼šä¸»é¢˜æœç´¢
    ],
    threshold: 0.3
};
```

### 3. æ·»åŠ æ–°çš„ç­›é€‰å™¨

åœ¨HTMLä¸­æ·»åŠ æ–°çš„ç­›é€‰ä¸‹æ‹‰èœå•ï¼š

```html
<!-- é£æ ¼ç­›é€‰ -->
<select id="styleFilter" class="form-select" onchange="filterByStyle()">
    <option value="">é€‰æ‹©é£æ ¼</option>
    <option value="è±ªæ”¾">è±ªæ”¾</option>
    <option value="å©‰çº¦">å©‰çº¦</option>
    <option value="ç”°å›­">ç”°å›­</option>
    <!-- æ›´å¤šé£æ ¼é€‰é¡¹ -->
</select>

<!-- åœºæ™¯ç­›é€‰ -->
<select id="sceneFilter" class="form-select" onchange="filterByScene()">
    <option value="">é€‰æ‹©åœºæ™¯</option>
    <option value="æ˜¥å¤©">æ˜¥å¤©</option>
    <option value="å¤œæ™š">å¤œæ™š</option>
    <option value="å±±æ°´">å±±æ°´</option>
    <!-- æ›´å¤šåœºæ™¯é€‰é¡¹ -->
</select>
```

### 4. æ·»åŠ ç­›é€‰å‡½æ•°

åœ¨JavaScriptä¸­æ·»åŠ æ–°çš„ç­›é€‰å‡½æ•°ï¼š

```javascript
// æŒ‰é£æ ¼ç­›é€‰
filterByStyle(style = null) {
    if (!style) {
        style = document.getElementById('styleFilter').value;
    }
    
    if (!style) {
        this.showAllPoems();
        return;
    }

    this.currentResults = this.poems.filter(poem => 
        poem.enhanced_tags && poem.enhanced_tags.styles.includes(style)
    );
    
    this.displayResults(this.currentResults, '', `é£æ ¼: ${style}`);
}

// æŒ‰åœºæ™¯ç­›é€‰
filterByScene(scene = null) {
    if (!scene) {
        scene = document.getElementById('sceneFilter').value;
    }
    
    if (!scene) {
        this.showAllPoems();
        return;
    }

    this.currentResults = this.poems.filter(poem => 
        poem.enhanced_tags && poem.enhanced_tags.scenes.includes(scene)
    );
    
    this.displayResults(this.currentResults, '', `åœºæ™¯: ${scene}`);
}
```

## è‡ªå®šä¹‰åˆ†æè§„åˆ™

### 1. æ·»åŠ æ–°çš„é£æ ¼å…³é”®è¯

åœ¨ `poem_analyzer.py` çš„ `setup_keywords` æ–¹æ³•ä¸­æ·»åŠ ï¼š

```python
self.style_keywords = {
    'è±ªæ”¾': ['è±ªæƒ…', 'å£®å¿—', 'è‹±é›„', ...],
    'å©‰çº¦': ['æŸ”æƒ…', 'ç›¸æ€', 'ç¦»åˆ«', ...],
    # æ·»åŠ æ–°çš„é£æ ¼
    'æµªæ¼«': ['æµªæ¼«', 'æ¢¦å¹»', 'æƒ³è±¡', 'å¥‡å¹»'],
    'ç°å®': ['ç°å®', 'çœŸå®', 'å®é™…', 'ç”Ÿæ´»']
}
```

### 2. è°ƒæ•´åˆ†ææƒé‡

ä¿®æ”¹åˆ†ææ–¹æ³•çš„è¯„åˆ†é€»è¾‘ï¼š

```python
def analyze_style(self, content, words):
    styles = []
    for style, keywords in self.style_keywords.items():
        # å¯ä»¥è°ƒæ•´è¯„åˆ†ç®—æ³•
        score = sum(content.count(keyword) * 2 for keyword in keywords)  # æƒé‡åŠ å€
        if score > 0:
            styles.append({
                'style': style,
                'score': score,
                'keywords_found': [kw for kw in keywords if kw in content]
            })
```

### 3. è‡ªå®šä¹‰å¤æ‚åº¦ç®—æ³•

ä¿®æ”¹ `calculate_complexity` æ–¹æ³•ï¼š

```python
def calculate_complexity(self, content, words):
    # åŸºäºæ›´å¤šå› ç´ è®¡ç®—å¤æ‚åº¦
    unique_words = len(set(word for word, flag in words))
    total_words = len(words)
    lexical_diversity = unique_words / total_words if total_words > 0 else 0
    
    # è€ƒè™‘å¥å­é•¿åº¦å˜åŒ–
    sentence_lengths = [len(p) for p in content.split('ï¼Œ')]
    length_variance = np.var(sentence_lengths) if len(sentence_lengths) > 1 else 0
    
    complexity = lexical_diversity * 8 + length_variance * 2
    return min(round(complexity, 2), 10)
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. åˆ†æ‰¹å¤„ç†
å¯¹äºå¤§é‡æ•°æ®ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†ï¼š

```python
def batch_analyze_with_chunks(self, poems_data, chunk_size=1000):
    """åˆ†æ‰¹å¤„ç†å¤§é‡æ•°æ®"""
    results = []
    total_chunks = (len(poems_data) + chunk_size - 1) // chunk_size
    
    for i in range(total_chunks):
        start = i * chunk_size
        end = start + chunk_size
        chunk = poems_data[start:end]
        
        print(f"å¤„ç†ç¬¬ {i+1}/{total_chunks} æ‰¹æ•°æ®...")
        chunk_results = self.batch_analyze(chunk)
        results.extend(chunk_results)
    
    return results
```

### 2. ç¼“å­˜åˆ†æç»“æœ
é¿å…é‡å¤åˆ†æï¼š

```python
import hashlib

def get_poem_hash(self, poem):
    """ç”Ÿæˆè¯—è¯å†…å®¹çš„å“ˆå¸Œå€¼ç”¨äºç¼“å­˜"""
    content = poem.get('title', '') + ' '.join(poem.get('paragraphs', []))
    return hashlib.md5(content.encode('utf-8')).hexdigest()
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**
   - è§£å†³æ–¹æ¡ˆï¼šå‡å°‘ `sample_size` æˆ–ä½¿ç”¨åˆ†æ‰¹å¤„ç†

2. **åˆ†è¯ä¸å‡†ç¡®**
   - è§£å†³æ–¹æ¡ˆï¼šåœ¨ `setup_jieba` æ–¹æ³•ä¸­æ·»åŠ æ›´å¤šè‡ªå®šä¹‰è¯å…¸

3. **åˆ†æç»“æœä¸ç†æƒ³**
   - è§£å†³æ–¹æ¡ˆï¼šè°ƒæ•´å…³é”®è¯åº“å’Œè¯„åˆ†é˜ˆå€¼

4. **æ–‡ä»¶ç¼–ç é—®é¢˜**
   - è§£å†³æ–¹æ¡ˆï¼šç¡®ä¿æ‰€æœ‰æ–‡ä»¶ä½¿ç”¨UTF-8ç¼–ç 

### è°ƒè¯•æŠ€å·§

1. ä½¿ç”¨æ¼”ç¤ºè„šæœ¬æµ‹è¯•å•é¦–è¯—è¯åˆ†æ
2. æ£€æŸ¥æ§åˆ¶å°è¾“å‡ºçš„é”™è¯¯ä¿¡æ¯
3. éªŒè¯è¾“å…¥æ•°æ®çš„æ ¼å¼å’Œå®Œæ•´æ€§
4. æ£€æŸ¥è¾“å‡ºæ–‡ä»¶çš„JSONæ ¼å¼

## æ‰©å±•åŠŸèƒ½

### 1. æœºå™¨å­¦ä¹ é›†æˆ
å¯ä»¥é›†æˆæœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œæ›´ç²¾ç¡®çš„åˆ†æï¼š

```python
# ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ
from transformers import pipeline

class AdvancedPoemAnalyzer(PoemAnalyzer):
    def __init__(self):
        super().__init__()
        self.sentiment_analyzer = pipeline('sentiment-analysis')
    
    def advanced_emotion_analysis(self, content):
        """ä½¿ç”¨æœºå™¨å­¦ä¹ è¿›è¡Œæƒ…æ„Ÿåˆ†æ"""
        result = self.sentiment_analyzer(content[:512])  # é™åˆ¶é•¿åº¦
        return result[0]
```

### 2. å¯è§†åŒ–åˆ†æ
ç”Ÿæˆåˆ†æç»“æœçš„å¯è§†åŒ–æŠ¥å‘Šï¼š

```python
import matplotlib.pyplot as plt

def generate_visualization(self, stats):
    """ç”Ÿæˆç»Ÿè®¡å¯è§†åŒ–"""
    # é£æ ¼åˆ†å¸ƒé¥¼å›¾
    styles = list(stats['style_distribution'].keys())
    counts = list(stats['style_distribution'].values())
    
    plt.figure(figsize=(10, 6))
    plt.pie(counts, labels=styles, autopct='%1.1f%%')
    plt.title('è¯—è¯é£æ ¼åˆ†å¸ƒ')
    plt.savefig('style_distribution.png')
```

---

é€šè¿‡æœ¬å·¥å…·ï¼Œæ‚¨å¯ä»¥ä¸ºã€Šå¾¡å®šå…¨å”è©©ã€‹æ•°æ®å¢åŠ ä¸°å¯Œçš„æ™ºèƒ½æ ‡ç­¾ï¼Œæå¤§æå‡æœç´¢å’Œåˆ†ç±»çš„ç²¾ç¡®åº¦ï¼Œä¸ºç”¨æˆ·æä¾›æ›´ä¼˜è´¨çš„è¯—è¯æ£€ç´¢ä½“éªŒã€‚